<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>
  <style>
    .navA{
      display: inline-block;
      margin-right: 13px;
      font-size: 16px;
      font-weight: 700;
      color: #000;
      text-decoration: none;
      padding: 5px ;
      border: #000 1px solid;
    }
    .navA:hover{
      color: #fff;
      background-color: #000;
    }
  </style>

  <title>Efficient Deep Learning Reading Group</title>

  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/ys_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Efficient Deep Learning Reading Group <a href="https://zhuanlan.zhihu.com/p/601150600" target=_blank> (知乎link)</a></heading> </name>


              </p>

              <p>
                Are you interested in efficient deep learning but find it hard to keep up with the latest research? Join our Efficient Deep Learning Reading Group! Our group is focused on reading and discussing the most important and influential papers in deep learning, with a special emphasis on efficiency and practical applications.

                By joining our group, you'll have the opportunity to:
            </p>

            <ul>
                <li><p> Stay up-to-date with the latest research in efficient deep learning, without having to spend countless hours sifting through papers on your own.
                </p>
                <li><p> Engage in thoughtful and productive discussions with other deep learning enthusiasts, sharing your insights and learning from others.
                </p>
                <li><p> Develop a deeper understanding of the key concepts and techniques in deep learning, and how they can be applied in real-world scenarios.
                </p>
                <li><p> Connect with like-minded individuals and build meaningful relationships with friends who are also interested in related fields.
                </p>
            </ul>
            <p>
                <font color="#FF8166">Our group meets once a week via Zoom, and sessions typically run for 60 minutes every Sunday at 9PM (EST) since Feb 26, 2023</font>. We welcome participants of all backgrounds and experience levels, as long as you have a basic understanding of deep learning fundamentals. To ensure a high-quality experience for all members, we do ask that you commit to attending regularly and actively participating in discussions.

                If you're interested in joining our group, please fill out the application form inside <a href="https://zhuanlan.zhihu.com/p/601150600" target=_blank> (知乎link)</a>. We look forward to hearing from you!
            </p>


              <p>
                Members:<br>
<!--                  <b><a href="https://eclipsess.github.io/yangsui.github.io/" target=_blank>Yang Sui</a></b>,-->
                  <b><a href="https://scholar.google.com/citations?user=HQw_pxwAAAAJ&hl=en" target=_blank>Wenjin Zhang</a></b><br>
                  <b><a href="https://scholar.google.com/citations?user=HxlbUgwAAAAJ&hl=en&oi=ao" target=_blank>Qizhen Ding</a></b><br>
                  <b><a href="https://scholar.google.com/citations?user=ibPjG1YAAAAJ&hl=en" target=_blank>Jiechao Gao</a></b><br>
                  <b><a href="" target=_blank>Ye Tao</a></b><br>
                  <b><a href="" target=_blank>Lujun Li</a></b><br>
                  <b><a href="" target=_blank>Yang Zheng</a></b><br>
                  <b><a href="https://sites.google.com/site/douxiaotianjason/" target=_blank>Xiaotian Dou</a></b><br>
                  <b><a href="" target=_blank>Jianwei Li </a></b><br>
                  <b><a href="" target=_blank>Yu Wu</a></b><br>
                  <b><a href="https://scholar.google.com/citations?user=nR-JqDAAAAAJ&hl=en" target=_blank>Xin Huang</a></b><br>
                  <b><a href="" target=_blank>Chengyuan Deng</a></b><br>
                  <b><a href="" target=_blank>Weizhao Jin</a></b><br>
                  <b><a href="" target=_blank>Xudong Wang</a></b><br>
                  <b><a href="" target=_blank>Zexing Xu</a></b><br>
                  <b><a href="" target=_blank>Yuhang Yao</a></b><br>
                  <b><a href="" target=_blank>Rulin Shao</a></b><br>
                  <b><a href="" target=_blank>Ruichao Li</a></b><br>
                  <b><a href="" target=_blank>Nianyi Wang</a></b><br>
                  <b><a href="" target=_blank>Xiang Pan</a></b><br>
                  <b><a href="https://github.com/ChulanZhang" target=_blank>Pengcheng Wang </a></b><br>
                  <b><a href="https://www.kaizhang.us/" target=_blank>Kai Zhang</a></b><br>
                  <b><a href="https://stevenboys.github.io/" target=_blank>Bowen Lei</a></b><br>
                  <b><a href="https://scholar.google.com/citations?user=iBnBTukAAAAJ&hl=en" target=_blank>Dan Liu</a></b><br>
                  <b><a href="" target=_blank>Yanfeng Qu</a></b><br>
                  <b><a href="liuchen1993.cn" target=_blank>Chen Liu</a></b><br>
                  <b><a href="https://scholar.google.com/citations?user=SrLu0TYAAAAJ&hl=en" target=_blank>Bin Hu</a></b><br>
                  <b><a href="http://huanwang.tech/" target=_blank>Huan Wang</a></b><br>
                  <b><a href="" target=_blank>Shan Xue</a></b><br>
                  <b><a href="http://qisunchn.top/" target=_blank>Qi Sun</a></b><br>
                  <b><a href="https://personal.utdallas.edu/~jxg170016/" target=_blank>Jufeng Guo</a></b><br>
                  <b><a href="" target=_blank>Yingcong Li</a></b><br>
                  <b><a href="chengyu-dong.me" target=_blank>Chengyu Dong</a></b><br>
                  <b><a href="" target=_blank>Rui Wang</a></b><br>

              </p>

              <p>
                  Organizer:<br>
                <b><a href="https://eclipsess.github.io/yangsui.github.io/" target=_blank>Yang Sui</a></b>
              </p>

<!--              <p>-->
<!--                  Howdy! I'm a fourth year Ph.D. student at <a href="https://www.ece.rutgers.edu/"> Rutgers University, ECE Department</a>, working on deep learning, machine learning and computer vision, advised by <a href="https://sites.google.com/site/boyuaneecs/">Prof. Bo Yuan</a>. I received my M.S. and B.E. at <a href="https://ee.jlu.edu.cn/">Jilin University</a>.-->
<!--              </p>-->

<!--              <p>-->
<!--                I'm currently a Research Intern at <a href="https://multimedia.tencent.com/">Media Lab, Tencent America</a>, working with <a href="https://scholar.google.com/citations?user=6glC_iEAAAAJ&hl=en">Dr. Ding Ding</a>, <a href="https://scholar.google.com/citations?user=w_BcpK8AAAAJ&hl=en">Prof. Zhenzhong Chen</a> since 2022, exploring efficient neural image compression and Transformer models. In 2019, I was a full-time Algorithm Engineer at <a href="https://corporate.jd.com/">JD</a>, working on the face verification and recognition. I also spent a wonderful time as a Research and Development Intern, initializing the deep learning inference framework <a href="https://github.com/PaddlePaddle/Paddle-Lite">Paddle-Lite</a> (<font color="#FF8166">6.4k stars now</font>) at <a href="https://en.wikipedia.org/wiki/Baidu">Baidu</a> in 2018.-->
<!--              </p>-->

<!--              <p style="text-align:center">-->
<!--                <a href="mailto:ys764@scarletmail.rutgers.edu">Email</a> &nbsp/&nbsp-->
<!--                <a href="Yang_files/YangSui_CV.pdf">CV (Feb 2023)</a> &nbsp/&nbsp-->
<!--                <a href="https://scholar.google.com/citations?user=Q2W1p6sAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp-->
<!--                <a href="https://www.linkedin.com/in/yang-sui-308055117/">LinkedIn</a> &nbsp&nbsp-->
<!--              </p>-->


<!--            </td>-->
<!--            <td style="padding:2.5%;width:40%;max-width:40%">-->
<!--              <a href="images/yangsui_cv.png"><img style="width:80%;max-width:80%" alt="profile photo" src="images/yangsui_cv.png" class="hoverZoomLink"></a>-->
<!--            </td>-->
          </tr>
        </tbody></table>

        <div class="navbar" style="padding-left: 18px;">
          <a href="#Feb 2023" class="navA">Feb 2023</a>
          <a href="#Mar 2023" class="navA">Mar 2023</a>
        </div>

<!--        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">-->
<!--        <tr>-->

<!--          <td width="100%" valign="middle">-->

<!--            <heading id="Research"><b>Research</b></heading>-->
<!--&lt;!&ndash;             <p>-->
<!--            I am interested in efficient & reliable deep learning for AI at scale, investigating how to improve the efficiency of deep learning systems to achieve Pareto optimality between computing resources (e.g., parameter, data, computation) and model performance (e.g., inference, training). My long-term research goal is to free AI from the parameter-data-computation hungry beasts, and democratize AI to serve a broader area and population.-->
<!--            </p> &ndash;&gt;-->
<!--            <p>-->
<!--            I'm interested in efficient deep learning, investigating how to optimize computational resources (e.g., parameters, data, computation) and model performance (e.g., inference, training).-->
<!--            </p>-->

<!--            <ul>-->
<!--            <li><p>-->
<!--              Efficient Training & Model Compression Algorithms-->
<!--              &lt;!&ndash; Neural Architecture Search, Pruning, Knowledge Distillation &ndash;&gt;-->
<!--            </p>-->
<!--            <li><p>-->
<!--              Algorithm-hardware Co-design for AI Acceleration-->
<!--              &lt;!&ndash; DeepLearning-hardware Co-design, Reduced-cost Training, Trainingless Proxies &ndash;&gt;-->
<!--            </p>-->
<!--            <li><p>-->
<!--              Efficient Vision Transformer-->
<!--              &lt;!&ndash; DeepLearning-hardware Co-design, Reduced-cost Training, Trainingless Proxies &ndash;&gt;-->
<!--            </p>-->
<!--            <li><p>-->
<!--              Neural Image Compression-->
<!--            </p>-->
<!--            <li><p>-->
<!--              Error Correct Coding-->
<!--            </p>-->

<!--            </ul>-->
<!--          </td>-->
<!--        </tr>-->


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>02/26/2023</h2>
            </td>
          </tr>

        </tbody></table>

        <table style="padding:20px;width:100%;vertical-align:middle"><tbody>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2201.13096" target=_blank>SPDY: Accurate Pruning with Speedup Guarantees</a></papertitle>, ICML'22.
              </a>
              <br>
              Elias Frantar, Dan Alistarh
<!--              <em><b>[ICML 2022]</b></em> <i>ICML 2022</i>-->
<!--              <br>-->
<!--              <a href="https://arxiv.org/abs/2206.08684">PDF</a>-->
              <p><b>Presenter: <a href="https://eclipsess.github.io/yangsui.github.io/" target=_blank><font color="#FF8166">Yang Sui</font></a></b>
              <br>
              <a href="Slides/YangSui-EDLRG-022623.pdf" target=_blank>Slides</a>
              </p>

            </td>
          </tr>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2206.08684" target=_blank>Sparse Double Descent: Where Network Pruning Aggravates Overfitting</a></papertitle>, ICML'22.
              </a>
              <br>
              Zheng He, Zeke Xie, Quanzhi Zhu, Zengchang Qin
              <p><b>Presenter: <a href="https://eclipsess.github.io/yangsui.github.io/" target=_blank><font color="#FF8166">Yang Sui</font></a></b>
                            <br>
              <a href="Slides/YangSui-EDLRG-022623.pdf" target=_blank>Slides</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2203.15794" target=_blank>CHEX: CHannel EXploration for CNN Model Compression</a></papertitle>, CVPR'22.
              </a>
              <br>
              Zejiang Hou, Minghai Qin, Fei Sun, Xiaolong Ma, Kun Yuan, Yi Xu, Yen-Kuang Chen, Rong Jin, Yuan Xie, Sun-Yuan Kung
              <p><b>Presenter: <a href="https://eclipsess.github.io/yangsui.github.io/" target=_blank><font color="#FF8166">Yang Sui</font></a></b>
                            <br>
              <a href="Slides/YangSui-EDLRG-022623.pdf" target=_blank>Slides</a>
              </p>
            </td>
          </tr>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>03/05/2023</h2>
            </td>
          </tr>
        </tbody></table>

        <table style="padding:20px;width:100%;vertical-align:middle"><tbody>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2006.01862" target=_blank>Consistent Estimators for Learning to Defer to an Expert</a></papertitle>, ICML'20.
              </a>
              <br>
              Hussein Mozannar, David Sontag
              <p><b>Presenter: <a href="" target=_blank><font color="#FF8166">Yu Wu</font></a></b></p>
            </td>
          </tr>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2006.16669" target=_blank>EasyQuant: Post-training Quantization via Scale Optimization</a></papertitle>, arXiv'20.
              </a>
              <br>
              Di Wu, Qi Tang, Yongle Zhao, Ming Zhang, Ying Fu, Debing Zhang
              <p><b>Presenter: <a href="" target=_blank><font color="#FF8166">Ruichao li</font></a></b></p>
            </td>
          </tr>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://sites.duke.edu/angli/files/2021/10/2021_Mobicom_Hermes_v1.pdf" target=_blank>Hermes: An Efficient Federated Learning Framework for Heterogeneous Mobile Clients</a></papertitle>, MobiCom'21.
              </a>
              <br>
              Ang Li, Jingwei Sun, Pengcheng Li, Yu Pu, Hai Li, Yiran Chen
              <p><b>Presenter: <a href="" target=_blank><font color="#FF8166">Bin Hu</font></a></b></p>
            </td>
          </tr>

                  <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/1906.02773" target=_blank>One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers</a></papertitle>, NeurIPS'19.
              </a>
              <br>
              Ari S. Morcos, Haonan Yu, Michela Paganini, Yuandong Tian
              <p><b>Presenter: <a href="" target=_blank><font color="#FF8166">Qizhen Ding</font></a></b></p>
            </td>
          </tr>

                  <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2301.12900" target=_blank>DepGraph: Towards Any Structural Pruning</a></papertitle>, CVPR'23.
              </a>
              <br>
              Gongfan Fang, Xinyin Ma, Mingli Song, Michael Bi Mi, Xinchao Wang
              <p><b>Presenter: <a href="" target=_blank><font color="#FF8166">Chengyuan Deng</font></a></b></p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>03/12/2023</h2>
            </td>
          </tr>
        </tbody></table>

        <table style="padding:20px;width:100%;vertical-align:middle"><tbody>


            <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2208.11580" target=_blank>Optimal Brain Compression: A Framework for Accurate Post-Training Quantization and Pruning</a></papertitle>, NeurIPS'22.
              </a>
              <br>
              Elias Frantar, Sidak Pal Singh, Dan Alistarh
              <p><b>Presenter: <a href="" target=_blank><font color="#FF8166">Jianwei Li</font></a></b>
              <br>
              <a href="Slides/OBC-Prune.pdf" target=_blank>Slides</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2206.14486" target=_blank>Beyond neural scaling laws: beating power law scaling via data pruning</a></papertitle>, NeurIPS'22.
              </a>
              <br>
              Ben Sorscher, Robert Geirhos, Shashank Shekhar, Surya Ganguli, Ari S. Morcos
              <p><b>Presenter: <a href="https://scholar.google.com/citations?user=HQw_pxwAAAAJ&hl=en" target=_blank><font color="#FF8166">Wenjin Zhang</font></a></b>
              <br>
              <a href="Slides/Beyond%20neural%20scaling%20laws%20beating%20power%20law%20scaling%20via%20data%20pruning.pdf" target=_blank>Slides</a>
              </p>
            </td>
          </tr>


          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="" target=_blank>HYDRA: Pruning Adversarially Robust Neural Networks</a></papertitle>, NeurIPS'20.
              </a>
              <br>
              Vikash Sehwag, Shiqi Wang, Prateek Mittal, Suman Jana
              <p><b>Presenter: <a href="https://personal.utdallas.edu/~jxg170016/" target=_blank><font color="#FF8166">Junfeng Guo</font></a></b></p>
            </td>
          </tr>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>03/19/2023</h2>
            </td>
          </tr>
        </tbody></table>

        <table style="padding:20px;width:100%;vertical-align:middle"><tbody>

            <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2302.06586" target=_blank>Stitchable Neural Networks</a></papertitle>, CVPR'23.
              </a>
              <br>
              Zizheng Pan, Jianfei Cai, Bohan Zhuang
              <p><b>Presenter: <a href="" target=_blank><font color="#FF8166">Lujun Li</font></a></b>
              <br>
              <a href="Slides/Stitchable%20Neural%20Networks-CVPR2023.pdf" target=_blank>Slides</a>
              </p>
            </td>
          </tr>

                  <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/pdf/2301.05219.pdf" target=_blank>Why is the State of Neural Network Pruning so Confusing? On the Fairness, Comparison Setup, and Trainability in Network Pruning</a></papertitle>.
              </a>
              <br>
              Huan Wang, Can Qin, Yue Bai, Yun Fu
              <p><b>Presenter: <a href="https://huanwang.tech/" target=_blank><font color="#FF8166">Huan Wang</font></a></b>
              <br>
              <a href="Slides/Efficient%20Deep%20Learning%20Reading%20Group%20%5B03_19_2023%5D.pdf" target=_blank>Slides</a>
              </p>
            </td>
          </tr>

                  <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/1912.13200" target=_blank>AdderNet: Do We Really Need Multiplications in Deep Learning?</a></papertitle>, CVPR'20.
              </a>
              <br>
              Hanting Chen, Yunhe Wang, Chunjing Xu, Boxin Shi, Chao Xu, Qi Tian, Chang Xu
              <p><b>Presenter: <a href="https://sqposeidon.github.io/" target=_blank><font color="#FF8166">Qi Sun</font></a></b>
              <br>
              <a href="Slides/Li_Searching_for_Energy-Efficient_Hybrid_Adder-Convolution_Neural_Networks_CVPRW_2022_paper.pdf" target=_blank>Slides</a>
              </p>
            </td>
          </tr>

          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>04/02/2023</h2>
            </td>
          </tr>
        </tbody></table>

          <table style="padding:20px;width:100%;vertical-align:middle"><tbody>

            <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://dl.acm.org/doi/pdf/10.1145/3560905.3568538" target=_blank>FedSEA: A Semi-Asynchronous Federated Learning Framework for Extremely Heterogeneous Devices</a></papertitle>, SenSys'22.
              </a>
              <br>
              Jingwei Sun, Ang Li, Lin Duan, Samiul Alam, Xuliang Deng, Xin Guo, Haiming Wang, Maria Gorlatova, Mi Zhang, Hai Li, Yiran Chen
              <p><b>Presenter: <a href="https://scholar.google.com/citations?user=ibPjG1YAAAAJ&hl=en" target=_blank><font color="#FF8166">Jiechao Gao</font></a></b>
              <br>
<!--              <a href="Slides/Stitchable%20Neural%20Networks-CVPR2023.pdf" target=_blank>Slides</a>-->
              </p>
            </td>
          </tr>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2302.04869" target=_blank>Reversible Vision Transformers</a></papertitle>, CVPR'22.
              </a>
              <br>
              Karttikeya Mangalam, Haoqi Fan, Yanghao Li, Chao-Yuan Wu, Bo Xiong, Christoph Feichtenhofer, Jitendra Malik
              <p><b>Presenter: <a href="https://www.kaizhang.us/" target=_blank><font color="#FF8166">Kai Zhang</font></a></b>
              <br>
              <a href="Slides/0402Rev-ViT.pdf" target=_blank>Slides</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2212.06152" target=_blank>Towards Efficient 3D Object Detection with Knowledge Distillation </a></papertitle>, NeurIPS'22.
              </a>
              <br>
              Jihan Yang, Shaoshuai Shi, Runyu Ding, Zhe Wang, Xiaojuan Qi
              <p><b>Presenter: <a href="https://github.com/ChulanZhang" target=_blank><font color="#FF8166">Pengcheng Wang</font></a></b>
              <br>
              <a href="Slides/0402Towards%20Efficient%203D%20Object%20Detection%20with%20Knowledge%20Distillation.pdf" target=_blank>Slides</a>
              </p>
            </td>
          </tr>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>04/09/2023</h2>
            </td>
          </tr>
        </tbody></table>

          <table style="padding:20px;width:100%;vertical-align:middle"><tbody>




          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2212.06152" target=_blank>Accelerating Dataset Distillation via Model Augmentation</a></papertitle>, CVPR'23.
              </a>
              <br>
              Lei Zhang, Jie Zhang, Bowen Lei, Subhabrata Mukherjee, Xiang Pan, Bo Zhao, Caiwen Ding, Yao Li, Dongkuan Xu
              <p><b>Presenter: <a href="https://stevenboys.github.io/" target=_blank><font color="#FF8166">Bowen Lei</font></a></b>
              <br>
              <a href="Slides/Fast_DD.pdf" target=_blank>Slides</a>
              </p>
            </td>
          </tr>


          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://www.usenix.org/system/files/nsdi21-sapio.pdf" target=_blank>Scaling Distributed Machine Learning with In-Network Aggregation</a></papertitle>, NSDI'21.
              </a>
              <br>
              Amedeo Sapio, Marco Canini, Chen-Yu Ho, Jacob Nelson, Panos Kalnis, Changhoon Kim, Arvind Krishnamurthy, Masoud Moshref, Dan Ports, Peter Richtarik
              <p><b>Presenter: <a href="" target=_blank><font color="#FF8166">Yanfeng Qu</font></a></b>
              <br>
              <a href="https://www.usenix.org/system/files/nsdi21_slides_sapio.pdf" target=_blank>Slides</a>
              </p>
            </td>
          </tr>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>04/16/2023</h2>
            </td>
          </tr>
        </tbody></table>

        <table style="padding:20px;width:100%;vertical-align:middle"><tbody>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2106.05945" target=_blank>Does Knowledge Distillation Really Work?</a></papertitle>, NeurIPS'21.
              </a>
              <br>
              Samuel Stanton, Pavel Izmailov, Polina Kirichenko, Alexander A. Alemi, Andrew Gordon Wilson
              <p><b>Presenter: <a href="https://www.chengyu-dong.me/" target=_blank><font color="#FF8166">Chengyu Dong</font></a></b>
              <br>
<!--              <a href="Slides/Fast_DD.pdf" target=_blank>Slides</a>-->
              </p>
            </td>
          </tr>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2201.12433" target=_blank>FedGCN: Convergence and Communication Tradeoffs in Federated Training of Graph Convolutional Networks</a></papertitle>.
              </a>
              <br>
              Yuhang Yao, Weizhao Jin, Srivatsan Ravi, Carlee Joe-Wong
              <p><b>Presenter: <a href="https://www.andrew.cmu.edu/user/yuhangya/" target=_blank><font color="#FF8166">Yuhang Yao</font></a></b>
              <br>
              <a href="Slides/FedGCN%20efficiency%20group.pdf" target=_blank>Slides</a>
              </p>
            </td>
          </tr>


        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>04/30/2023</h2>
            </td>
          </tr>
        </tbody></table>

        <table style="padding:20px;width:100%;vertical-align:middle"><tbody>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2110.04366" target=_blank>Towards a Unified View of Parameter-Efficient Transfer Learning</a></papertitle>, ICLR'22.
              </a>
              <br>
              Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, Graham Neubig
              <p><b>Presenter: <a href="" target=_blank><font color="#FF8166">Xiang Pan</font></a></b>
              <br>
<!--              <a href="Slides/Fast_DD.pdf" target=_blank>Slides</a>-->
              </p>
            </td>
          </tr>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2103.02143" target=_blank>Random Feature Attention</a></papertitle>, ICLR'21.
              </a>
              <br>
              Hao Peng, Nikolaos Pappas, Dani Yogatama, Roy Schwartz, Noah A. Smith, Lingpeng Kong
              <p><b>Presenter: <a href="" target=_blank><font color="#FF8166">Yingcong Li</font></a></b>
              <br>
<!--              <a href="Slides/FedGCN%20efficiency%20group.pdf" target=_blank>Slides</a>-->
              </p>
            </td>
          </tr>

                    <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://www.usenix.org/conference/atc20/presentation/zhang-chengliang" target=_blank>BatchCrypt: Efficient Homomorphic Encryption for Cross-Silo Federated Learning</a></papertitle>, ATC'20.
              </a>
              <br>
              Chengliang Zhang, Suyi Li, Junzhe Xia, and Wei Wang
              <p><b>Presenter: <a href="" target=_blank><font color="#FF8166">Weizhao Jin</font></a></b>
              <br>
<!--              <a href="Slides/FedGCN%20efficiency%20group.pdf" target=_blank>Slides</a>-->
              </p>
            </td>
          </tr>


        </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>05/14/2023</h2>
            </td>
          </tr>
        </tbody></table>

        <table style="padding:20px;width:100%;vertical-align:middle"><tbody>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2211.10438" target=_blank>SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</a></papertitle>.
              </a>
              <br>
              Guangxuan Xiao, Ji Lin, Mickael Seznec, Hao Wu, Julien Demouth, Song Han
              <p><b>Presenter: <a href="" target=_blank><font color="#FF8166">Yang Sui</font></a></b>
              <br>
<!--              <a href="Slides/Fast_DD.pdf" target=_blank>Slides</a>-->
              </p>
            </td>
          </tr>

          <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2304.01089" target=_blank>RPTQ: Reorder-based Post-training Quantization for Large Language Models</a></papertitle>.
              </a>
              <br>
              Zhihang Yuan, Lin Niu, Jiawei Liu, Wenyu Liu, Xinggang Wang, Yuzhang Shang, Guangyu Sun, Qiang Wu, Jiaxiang Wu, Bingzhe Wu
              <p><b>Presenter: <a href="" target=_blank><font color="#FF8166">Yang Sui</font></a></b>
              <br>
<!--              <a href="Slides/FedGCN%20efficiency%20group.pdf" target=_blank>Slides</a>-->
              </p>
            </td>
          </tr>

                    <tr>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><a href="https://arxiv.org/abs/2201.03514" target=_blank>Black-Box Tuning for Language-Model-as-a-Service</a></papertitle>, ICML'22.
              </a>
              <br>
              Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, Xipeng Qiu
              <p><b>Presenter: <a href="" target=_blank><font color="#FF8166">Rui Wang</font></a></b>
              <br>
<!--              <a href="Slides/FedGCN%20efficiency%20group.pdf" target=_blank>Slides</a>-->
              </p>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:0px">
              <br><hr width=80%>
              <p style="text-align:right;font-size:small;">
                *Last updated on 2023*
                <br>
                <a href="https://jonbarron.info/" target=_blank>Inspired by Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
